{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from colour.notation import HEX_to_RGB\n",
    "from colour import convert, describe_conversion_path, delta_E\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# set seeds\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "# sns.set(style = 'darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "def create_new_features(X):\n",
    "    # transform utc offset:\n",
    "    X['Sin_UTC'] = np.sin((11 * 3600 + X['UTC Offset']) / (24 * 3600) * 2 * np.pi)\n",
    "    X['Cos_UTC'] = np.cos((11 * 3600 + X['UTC Offset']) / (24 * 3600) * 2 * np.pi)\n",
    "    \n",
    "    # time since creation in days\n",
    "    duration = (pd.to_datetime('today') - \n",
    "                pd.to_datetime(X['Profile Creation Timestamp']).dt.tz_localize(None))\n",
    "    X['Duration'] = duration.apply(lambda x: x.days)\n",
    "    \n",
    "    # convert personal url into True/False (NaNs or unique)\n",
    "    X['Has Personal URL'] = X['Personal URL'].notna()\n",
    "    \n",
    "    # log(x + 1) of numerical features\n",
    "    for feature in ['Num of Followers', 'Num of People Following',\n",
    "                    'Num of Status Updates', 'Num of Direct Messages',\n",
    "                    'Avg Daily Profile Visit Duration in seconds',\n",
    "                    'Avg Daily Profile Clicks']:\n",
    "        X[f'log {feature}'] = np.log1p(X[feature])\n",
    "    \n",
    "    for col in ['Profile Text Color', 'Profile Page Color', 'Profile Theme Color']:\n",
    "        # X[f'Lab {col}'] = X[col].apply(lambda x: HEX_to_RGB(x) if not pd.isnull(x) \n",
    "        #         else np.array((1,1,1)))\n",
    "        X[f'Lab {col}'] = X[col].apply(lambda x: convert(HEX_to_RGB(x), 'RGB', 'CIE Lab') if not pd.isnull(x) \n",
    "                else convert((1,1,1), 'RGB', 'CIE Lab'))\n",
    "\n",
    "    return X\n",
    "    \n",
    "def clean_features(X):\n",
    "    # merge categories names with and without cap letter\n",
    "    X['Location Public Visibility'] = X['Location Public Visibility'].str.lower()\n",
    "    X.loc[X['Profile Category'] == \" \", 'Profile Category'] = 'unknown'\n",
    "    return X\n",
    "\n",
    "def drop_features(X, l_features):\n",
    "    return X.drop(columns=l_features)\n",
    "    \n",
    "class RemoveCategories(TransformerMixin):\n",
    "    def __init__(self, min_obs=10, l_cols=[]):\n",
    "        self.min_obs = min_obs\n",
    "        self.l_cats = {}\n",
    "        self.l_cols = l_cols\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            # Simple optimization to gain speed (inspect is slow)\n",
    "            return self\n",
    "        valid_params = {'min_obs':'min_obs'}\n",
    "        setattr(self, 'min_obs', params['min_obs'])\n",
    "       \n",
    "        return self\n",
    "\n",
    "    def fit(self, X):\n",
    "        # assumes all columns of df_cat are strings\n",
    "        for col in self.l_cols:\n",
    "            val_counts = X[col].fillna('missing').value_counts()\n",
    "            self.l_cats[col] = val_counts[val_counts >= self.min_obs].index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        for col in self.l_cols:\n",
    "            X.loc[~ X[col].isin(self.l_cats[col]), col] = 'other'        \n",
    "        return X\n",
    "\n",
    "class ClusterColors(TransformerMixin):\n",
    "    \"\"\" The data in X[ccols] should be CIE Lab color data\"\"\"\n",
    "    def __init__(self, ccols=['Lab Profile Text Color', 'Lab Profile Page Color', 'Lab Profile Theme Color'], *args, **kwargs):\n",
    "        self.clusterers = dict(zip(ccols, [KMeans(*args, **kwargs)]*len(ccols)))\n",
    "        self.columns = ccols\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for clusterer in self.clusterers.values():\n",
    "            clusterer.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):        \n",
    "        for col in self.columns:\n",
    "            self.clusterers[col].fit(list(X[col].to_numpy()))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            X[f'Clustered {col}'] = self.clusterers[col].predict(list(X[col].to_numpy()))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "ccols = ['Profile Text Color', 'Profile Page Color',\n",
    "               'Profile Theme Color']\n",
    "clab = ['Lab '+cc for cc in ccols]\n",
    "l_cat_small = ['User Language']\n",
    "\n",
    "\n",
    "features_to_drop =dict(l_features = ['Id', 'User Name', 'Profile Image',\n",
    "                                     'Personal URL', 'UTC Offset', \n",
    "                                     'Profile Creation Timestamp',\n",
    "                                     'User Time Zone', 'Location']+ccols)\n",
    "static_pipe = Pipeline([('create new features',\n",
    "                  FunctionTransformer(create_new_features)),\n",
    "                 ('clean data', FunctionTransformer(clean_features)),\n",
    "                #  ('cluster', ClusterColors(n_clusters=7, n_init=10, max_iter=300, tol=1e-4)),\n",
    "                 ('remove categories', RemoveCategories(min_obs=2, \n",
    "                                                        l_cols=l_cat_small)),\n",
    "                 ('drop variables', FunctionTransformer(drop_features,\n",
    "                                    kw_args=features_to_drop))\n",
    "                ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# numerical features\n",
    "ccols = ['Lab Profile Text Color', 'Lab Profile Page Color',\n",
    "               'Lab Profile Theme Color',]\n",
    "num_features = list(X.select_dtypes(exclude=['object', 'bool']).columns)\n",
    "# num_features.append(pd.Index(ccols))\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "catcols = list(X.select_dtypes(include=['object', 'bool']).columns) #+ ['Clustered '+c for c in ccols]\n",
    "print(catcols)\n",
    "cat_features = list([col for col in catcols if col not in ccols])\n",
    "\n",
    "# categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False))])\n",
    "\n",
    "# preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numeric_transformer, num_features),\n",
    "                  ('cat', categorical_transformer, cat_features)])\n",
    "\n",
    "# X2 = pd.DataFrame(X_t, columns=get_ct_feature_names(preprocessor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "y = np.log1p(df['Num of Profile Likes'].values)\n",
    "X = df.drop(columns='Num of Profile Likes')\n",
    "\n",
    "X = static_pipe.fit_transform(X)\n",
    "\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.\n",
    "\n",
    "parameters = {\n",
    "    'base_estimator__n_neighbors': range(2,6),\n",
    "    'base_estimator__weights': ['uniform', 'distance'],\n",
    "    'base_estimator__p': [1,2,3,4],\n",
    "    'max_features': [0.3,0.4,0.5,0.6],\n",
    "    'max_samples': [0.3,0.4,0.5,0.6],\n",
    "    'max_samples': [0.3,0.4,0.5,0.6],\n",
    "    'bootstrap_features': [True, False],\n",
    "    'bootstrap': [True, False],\n",
    "    # 'cluster__n_clusters': range(2,5)\n",
    "    }\n",
    "\n",
    "br = BaggingRegressor(max_features=0.5, base_estimator=KNeighborsRegressor(n_neighbors=3, p=3, weights='distance'))\n",
    "br_cv = GridSearchCV(br, param_grid=parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "br_cv.fit(X, y)\n",
    "print(np.sqrt(-br_cv.best_score_), br_cv.best_params_)"
   ]
  }
 ]
}