{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third submission: Gradient Boosting\n",
    " * min observations in each category: 2\n",
    " * RMSLE: 1.715\n",
    " * best parameters: {'n_iter_no_change': 6, 'n_estimators': 10000, 'min_samples_split': 21, 'min_samples_leaf': 9, 'max_depth': 5, 'learning_rate': 0.06}\n",
    " * wasn't able to use xgboost with early stopping and cross validations (used sklearn's version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:21.432195Z",
     "start_time": "2020-12-12T20:23:20.157828Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# set seeds\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and drop features, manage categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:22.374418Z",
     "start_time": "2020-12-12T20:23:22.172751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "def create_new_features(X):\n",
    "    # transform utc offset:\n",
    "    X['Sin_UTC'] = np.sin((11 * 3600 + X['UTC Offset']) / (24 * 3600) * 2 * np.pi)\n",
    "    X['Cos_UTC'] = np.cos((11 * 3600 + X['UTC Offset']) / (24 * 3600) * 2 * np.pi)\n",
    "    \n",
    "    # time since creation in days\n",
    "    duration = (pd.to_datetime('today') - \n",
    "                pd.to_datetime(X['Profile Creation Timestamp']).dt.tz_localize(None))\n",
    "    X['Duration'] = duration.apply(lambda x: x.days)\n",
    "    \n",
    "    # convert personal url into True/False (NaNs or unique)\n",
    "    X['Has Personal URL'] = X['Personal URL'].notna()\n",
    "    \n",
    "    # log(x + 1) of numerical features\n",
    "    for feature in ['Num of Followers', 'Num of People Following',\n",
    "                    'Num of Status Updates', 'Num of Direct Messages',\n",
    "                    'Avg Daily Profile Visit Duration in seconds',\n",
    "                    'Avg Daily Profile Clicks']:\n",
    "        X[f'log {feature}'] = np.log1p(X[feature])\n",
    "    return X\n",
    "    \n",
    "def clean_features(X):\n",
    "    # merge categories names with and without cap letter\n",
    "    X['Location Public Visibility'] = X['Location Public Visibility'].str.lower()\n",
    "    X.loc[X['Profile Category'] == \" \", 'Profile Category'] = 'unknown'\n",
    "    return X\n",
    "\n",
    "def drop_features(X, l_features):\n",
    "    return X.drop(columns=l_features)\n",
    "    \n",
    "class RemoveCategories(TransformerMixin):\n",
    "    def __init__(self, min_obs=10, l_cols=[]):\n",
    "        self.min_obs = min_obs\n",
    "        self.l_cats = {}\n",
    "        self.l_cols = l_cols\n",
    "\n",
    "    def fit(self, X):\n",
    "        # assumes all columns of df_cat are strings\n",
    "        for col in self.l_cols:\n",
    "            val_counts = X[col].fillna('missing').value_counts()\n",
    "            self.l_cats[col] = val_counts[val_counts >= self.min_obs].index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        for col in self.l_cols:\n",
    "            X.loc[~ X[col].isin(self.l_cats[col]), col] = 'other'        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:24.544055Z",
     "start_time": "2020-12-12T20:23:24.517023Z"
    }
   },
   "outputs": [],
   "source": [
    "# data cleaning and feature engineering\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "l_cat_small = ['Profile Text Color', 'Profile Page Color',\n",
    "               'Profile Theme Color', 'User Language', 'Location']\n",
    "l_drop = ['Id', 'User Name', 'Profile Image', 'Personal URL',\n",
    "          'Profile Creation Timestamp', 'Location', 'UTC Offset']\n",
    "l_drop_logs = ['Num of Followers', 'Num of People Following',\n",
    "               'Num of Status Updates', 'Num of Direct Messages',\n",
    "               'Avg Daily Profile Visit Duration in seconds', \n",
    "               'Avg Daily Profile Clicks']\n",
    "\n",
    "features_to_drop =dict(l_features = l_drop + l_drop_logs)\n",
    "\n",
    "pipe = Pipeline([('create new features',\n",
    "                  FunctionTransformer(create_new_features)),\n",
    "                 ('clean data', FunctionTransformer(clean_features)),\n",
    "                 ('remove categories', RemoveCategories(min_obs=2, \n",
    "                                                        l_cols=l_cat_small)),\n",
    "                 ('drop variables', FunctionTransformer(drop_features,\n",
    "                                    kw_args=features_to_drop))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation and encoding/scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:26.785473Z",
     "start_time": "2020-12-12T20:23:26.661286Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# numerical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:31.402324Z",
     "start_time": "2020-12-12T20:23:29.924426Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "y = np.log1p(df['Num of Profile Likes'].values)\n",
    "X = df.drop(columns='Num of Profile Likes')\n",
    "\n",
    "X = pipe.fit_transform(X)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numeric_transformer,\n",
    "                   X.select_dtypes(exclude=['object', 'bool']).columns),\n",
    "                  ('cat', categorical_transformer,\n",
    "                   X.select_dtypes(include=['object', 'bool']).columns)])\n",
    "\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=100)]: Using backend LokyBackend with 100 concurrent workers.\n",
      "[Parallel(n_jobs=100)]: Done  21 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=100)]: Done  42 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=100)]: Done  65 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=100)]: Done  88 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=100)]: Done 113 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=100)]: Done 138 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=100)]: Done 165 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=100)]: Done 192 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=100)]: Done 221 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=100)]: Done 250 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=100)]: Done 281 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=100)]: Done 352 out of 500 | elapsed:  1.4min remaining:   34.5s\n",
      "[Parallel(n_jobs=100)]: Done 403 out of 500 | elapsed:  1.6min remaining:   22.8s\n",
      "[Parallel(n_jobs=100)]: Done 454 out of 500 | elapsed:  1.7min remaining:   10.2s\n",
      "[Parallel(n_jobs=100)]: Done 500 out of 500 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE: 1.715 \n",
      "best parameters: {'n_iter_no_change': 6, 'n_estimators': 10000, 'min_samples_split': 21, 'min_samples_leaf': 9, 'max_depth': 5, 'learning_rate': 0.06}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb= GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "parameters = {'n_estimators': [10000],\n",
    "              'n_iter_no_change': [6, 8, 10],\n",
    "              'learning_rate': [0.06, 0.07],\n",
    "              'min_samples_split': range(8, 25),\n",
    "              'min_samples_leaf': range(3, 10),\n",
    "              'max_depth': range(3, 7)}\n",
    "\n",
    "reg_gb = RandomizedSearchCV(gb, parameters, scoring='neg_mean_squared_error',\n",
    "                            n_jobs=100, random_state=0, n_iter=100, verbose=10)\n",
    "reg_gb.fit(X, y)\n",
    "\n",
    "print(f'RMSLE: {np.sqrt(-reg_gb.best_score_):.3f}',\n",
    "      f'\\nbest parameters: { reg_gb.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:07.576617Z",
     "start_time": "2020-12-12T20:23:07.569636Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_submission(estimator, number):\n",
    "    X_test = pd.read_csv('data/test.csv')\n",
    "    Id = X_test['Id']\n",
    "    X_test = pipe.transform(X_test)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    y_pred = (estimator.predict(X_test))\n",
    "    y_pred_test = pd.Series(np.expm1(y_pred))\n",
    "    submission = pd.DataFrame({'Id': Id, 'Predicted': y_pred_test})\n",
    "    path = f'submissions/submission{number}.csv'\n",
    "    while os.path.exists(path):\n",
    "        number += 1\n",
    "        path = f'submissions/submission{number}.csv'\n",
    "    submission.to_csv(path, index=False)\n",
    "    print(f'submission #{number} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:07.745663Z",
     "start_time": "2020-12-12T20:23:07.579936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission #3 created\n"
     ]
    }
   ],
   "source": [
    "create_submission(reg_gb, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T20:23:07.747820Z",
     "start_time": "2020-12-12T20:23:07.573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49I3SOKLI2CMNGP4</td>\n",
       "      <td>3805.131066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>727IRIR59A3P88LK</td>\n",
       "      <td>2397.606135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LN95SD15SRPCEE8F</td>\n",
       "      <td>518.503607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TB11I7F0PN033D4T</td>\n",
       "      <td>3660.776378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32PSGCK5PATHMR07</td>\n",
       "      <td>198.484124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id    Predicted\n",
       "0  49I3SOKLI2CMNGP4  3805.131066\n",
       "1  727IRIR59A3P88LK  2397.606135\n",
       "2  LN95SD15SRPCEE8F   518.503607\n",
       "3  TB11I7F0PN033D4T  3660.776378\n",
       "4  32PSGCK5PATHMR07   198.484124"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submissions/submission3.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "kaggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
